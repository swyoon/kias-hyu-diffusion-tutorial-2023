{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3556433d-c509-403d-be6a-b852356d25c9",
   "metadata": {},
   "source": [
    "# Diffusion Model Hands-On Tutorial\n",
    "\n",
    "**Sangwoong Yoon** (AI Research Fellow @ KIAS; http://swyoon.github.io )\n",
    "\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/swyoon/kias-hyu-diffusion-tutorial-2023/blob/main/diffusion_model_hands_on.ipynb)\n",
    "\n",
    "**Abstract**\n",
    "\n",
    "> Today, we will study a minimal working example of [Denoising Diffusion Probabilistic Model (DDPM); Ho et al., 2020](https://arxiv.org/abs/2006.11239).\n",
    "> Instead of reproducing fancy results from large-scale models, we shall focus on understanding what is exactly going on inside a very small model.\n",
    "> We will run a vanilla DDPM on 2D datasets and investigate when it works well and when it doesn't.\n",
    "\n",
    "\n",
    "\n",
    "**Table of Contents**\n",
    "\n",
    "1. Data Generation\n",
    "2. Diffusion\n",
    "3. DDPM\n",
    "4. Neural Networks\n",
    "5. Training\n",
    "6. Performance Evaluation\n",
    "\n",
    "**Exercise**\n",
    "\n",
    "* Vary the following variables and see if the performance remains the same:\n",
    "    * dataset\n",
    "    * the number of diffusion time steps\n",
    "    * beta (sigma) schedule\n",
    "    * scale of data\n",
    "    * the number of diffusion time steps\n",
    "\n",
    "**Further Reading**\n",
    "\n",
    "* https://github.com/openai/guided-diffusionhttps://github.com/openai/guided-diffusion\n",
    "* https://github.com/CompVis/latent-diffusionhttps://github.com/CompVis/latent-diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a52777-09f8-4906-9ce9-1cf6d068ca09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4d62d5-9f27-4fee-b489-8583cfa625a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.distributions import Normal\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1895963-83af-411e-81ed-7534bf481916",
   "metadata": {},
   "source": [
    "## 1. Dataset Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3420e6-8a10-4aff-826f-cfa690513104",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = '8gaussians'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db943da8-948b-4166-be2d-271204f02bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Synthetic distributions from https://github.com/nicola-decao/BNAF/\n",
    "'''\n",
    "def sample2d(data, batch_size=200, scale_factor=1.):\n",
    "    rng = np.random.RandomState()\n",
    " \n",
    "    if data == '8gaussians':\n",
    "        scale = 4.\n",
    "        centers = [(1, 0), (-1, 0), (0, 1), (0, -1), (1. / np.sqrt(2), 1. / np.sqrt(2)),\n",
    "                   (1. / np.sqrt(2), -1. / np.sqrt(2)), (-1. / np.sqrt(2),\n",
    "                                                         1. / np.sqrt(2)), (-1. / np.sqrt(2), -1. / np.sqrt(2))]\n",
    "        centers = [(scale * x, scale * y) for x, y in centers]\n",
    "\n",
    "        dataset = []\n",
    "        for i in range(batch_size):\n",
    "            point = rng.randn(2) * 0.5\n",
    "            idx = rng.randint(8)\n",
    "            center = centers[idx]\n",
    "            point[0] += center[0]\n",
    "            point[1] += center[1]\n",
    "            dataset.append(point)\n",
    "        dataset = np.array(dataset, dtype='float32')\n",
    "        dataset /= 1.414\n",
    "        dataset *= scale_factor\n",
    "        return dataset\n",
    "\n",
    "    elif data == '2spirals':\n",
    "        n = np.sqrt(np.random.rand(batch_size // 2, 1)) * 540 * (2 * np.pi) / 360\n",
    "        d1x = -np.cos(n) * n + np.random.rand(batch_size // 2, 1) * 0.5\n",
    "        d1y = np.sin(n) * n + np.random.rand(batch_size // 2, 1) * 0.5\n",
    "        x = np.vstack((np.hstack((d1x, d1y)), np.hstack((-d1x, -d1y)))) / 3\n",
    "        x += np.random.randn(*x.shape) * 0.1\n",
    "        x *= scale_factor\n",
    "        return x\n",
    "\n",
    "    elif data == 'checkerboard':\n",
    "        x1 = np.random.rand(batch_size) * 4 - 2\n",
    "        x2_ = np.random.rand(batch_size) - np.random.randint(0, 2, batch_size) * 2\n",
    "        x2 = x2_ + (np.floor(x1) % 2)\n",
    "        dataset = np.concatenate([x1[:, None], x2[:, None]], 1) * 2\n",
    "        dataset *= scale_factor\n",
    "        return dataset\n",
    " \n",
    "    else:\n",
    "        raise RuntimeError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b6aadb-6ff6-47b4-86a4-d1c26b2f06fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''visualize datasets'''\n",
    "fig, axs = plt.subplots(ncols=3, figsize=(12, 4))\n",
    "x = torch.tensor(sample2d('8gaussians', batch_size=1000, scale_factor=1.))\n",
    "axs[0].scatter(x[:,0], x[:,1])\n",
    "x = torch.tensor(sample2d('2spirals', batch_size=1000, scale_factor=1.))\n",
    "axs[1].scatter(x[:,0], x[:,1])\n",
    "x = torch.tensor(sample2d('checkerboard', batch_size=1000, scale_factor=1.))\n",
    "axs[2].scatter(x[:,0], x[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e2eb93-0512-4196-bcae-d51636af37c3",
   "metadata": {},
   "source": [
    "## 2. Diffusion\n",
    "\n",
    "$$\n",
    "x_{t} = \\sqrt{1-\\sigma_t^2} \\cdot x_{t-1} + \\sigma_t \\epsilon, \\epsilon \\sim \\mathcal{N}(0, I)\n",
    "$$\n",
    "\n",
    "We will mainly write with respect to beta_t = sigma_t^2.\n",
    "\n",
    "In the paper, $t \\in \\{1,\\ldots,T\\}$.  \n",
    "However, computers (and also computer scientists) counts from 0. So keep in mind that the index 0 corresponds to $t=1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bc806b-0cc8-4c8b-897a-a096c55ef1e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Define a sequence of sigma_t's.\n",
    "'''\n",
    "def make_beta_schedule(schedule='linear', n_timesteps=1000, start=1e-5, end=1e-2):\n",
    "    if schedule == 'linear':\n",
    "        betas = torch.linspace(start, end, n_timesteps)\n",
    "    elif schedule == \"quad\":\n",
    "        betas = torch.linspace(start ** 0.5, end ** 0.5, n_timesteps) ** 2\n",
    "    elif schedule == \"constant\":\n",
    "        betas = torch.ones(n_timesteps) * start \n",
    "    return betas\n",
    "\n",
    "\n",
    "def extract(var, t, x):\n",
    "    shape = x.shape\n",
    "    out = torch.gather(var, 0, t.to(var.device))\n",
    "    reshape = [t.shape[0]] + [1] * (len(shape) - 1)\n",
    "    return out.reshape(*reshape).to(x.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03af109f-d411-491b-a533-a38349332a7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"initialize diffusion-related constant\"\"\"        \n",
    "beta_schedule = 'linear'\n",
    "n_timesteps = 10\n",
    "beta_start, beta_end = 1e-3, 1e-2\n",
    "betas = make_beta_schedule(\n",
    "    schedule=beta_schedule,\n",
    "    n_timesteps=n_timesteps,\n",
    "    start=beta_start,\n",
    "    end=beta_end,\n",
    ")    \n",
    "\n",
    "alphas = 1 - betas\n",
    "alphas_prod = torch.cumprod(alphas, 0)\n",
    "alphas_prod_p = torch.cat([torch.tensor([1]).float(), alphas_prod[:-1]], 0)\n",
    "alphas_bar_sqrt = torch.sqrt(alphas_prod)\n",
    "one_minus_alphas_bar_log = torch.log(1 - alphas_prod)\n",
    "one_minus_alphas_bar_sqrt = torch.sqrt(1 - alphas_prod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34f7764-074f-4c61-9883-a5ebe7098dc6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def q_sample(x_start, t):\n",
    "    \"\"\"\n",
    "    Diffuse the data (t == 0 means diffused for 1 step)\n",
    "    \"\"\"\n",
    "    global alphas_bar_sqrt, one_minus_alphas_bar_sqrt\n",
    "    noise = torch.randn(*x_start.shape, device=x_start.device)\n",
    "    x_t = extract(alphas_bar_sqrt, t, x_start) * x_start + extract(one_minus_alphas_bar_sqrt, t, x_start) * noise\n",
    "    return x_t\n",
    "\n",
    "def q_sample_progressive(x_0, n_timesteps):\n",
    "    \"\"\"Generate a full sequence of perturbed samples\"\"\"\n",
    "    x_preds = []\n",
    "    for t in range(n_timesteps):\n",
    "        t_now = torch.ones(x_0.shape[0], device=x_0.device, dtype=torch.long) * t\n",
    "        x_t = q_sample(x_0, t_now)\n",
    "        x_preds.append(x_t)\n",
    "    x_preds = torch.stack(x_preds, dim=0)\n",
    "    return x_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12f644f-4562-4534-8b86-0cc995eaf9c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''visualize diffusion process'''\n",
    "x = torch.tensor(sample2d(dataset, batch_size=500))\n",
    "x_diffused = q_sample_progressive(x, n_timesteps)\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(ncols=5, figsize=(20, 4))\n",
    "axs[0].scatter(x[:,0], x[:,1])\n",
    "axs[0].set_title('t=0 (data)')\n",
    "axs[0].set_xlim([-4,4])\n",
    "axs[0].set_ylim([-4,4])\n",
    "\n",
    "for i_plot in [1, 2, 3]:\n",
    "    t = n_timesteps // 4 * i_plot \n",
    "    xx = x_diffused[t]\n",
    "    axs[i_plot].scatter(xx[:,0], xx[:,1])\n",
    "    axs[i_plot].set_title(f't={t+1}')\n",
    "    axs[i_plot].set_xlim([-4,4])\n",
    "    axs[i_plot].set_ylim([-4,4])\n",
    "\n",
    "xx = x_diffused[-1]\n",
    "axs[4].scatter(xx[:,0], xx[:,1])\n",
    "axs[4].set_title(f't={n_timesteps} (Should be Gaussian)')\n",
    "axs[4].set_xlim([-4,4])\n",
    "axs[4].set_ylim([-4,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfcdfad8-0129-48a6-bcac-ec63ab082f63",
   "metadata": {},
   "source": [
    "## 3. DDPM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4510ade1-f153-4725-af26-5262fb79f02c",
   "metadata": {},
   "source": [
    "![](ddpm_algorithm.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c2b458-b1a0-4792-8fb5-9854cef23053",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DDPM(nn.Module):\n",
    "    \"\"\"a minimal working DDPM\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        sampler,\n",
    "        n_timesteps,\n",
    "        sample_shape,\n",
    "        beta_schedule=\"sigmoid\",\n",
    "        beta_start=1e-5,\n",
    "        beta_end=1e-2,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        sampler: a diffusion-like sampler. nn.Module.\n",
    "        value: value function. nn.Module.\n",
    "        n_timesteps: number of timesteps\n",
    "        sample_shape: shape of the samples\n",
    "\n",
    "        <Diffusion parameters>\n",
    "        beta_schedule: diffusion noise shcedule. 'linear', 'quad', 'sigmoid', 'constant'\n",
    "        reg_vel: velocity regularization.\n",
    "        ddpm_like: if True, a sample is generated via diffusion-like update rule.\n",
    "            x_{t-1} = 1/sqrt{alpha_t} (x_{t} - (1-alpha_t/sqrt{1-bar{alpha}_t}) * net(x_t,t)) + sigma_t * eps_t,\n",
    "            if False, x_{t-1} = x_t - net(x_t,t) + sigma_t * eps_t.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        betas = make_beta_schedule(\n",
    "            schedule=beta_schedule,\n",
    "            n_timesteps=n_timesteps,\n",
    "            start=beta_start,\n",
    "            end=beta_end,\n",
    "        )\n",
    "        self.register_buffer(\"betas\", betas)\n",
    "        self.init_beta()\n",
    "        self.sampler = sampler\n",
    "        self.sample_shape = sample_shape\n",
    "        self.n_timesteps = n_timesteps\n",
    "        \n",
    "    def init_beta(self):\n",
    "        \"\"\"initialize DDPM related constants\"\"\"\n",
    "        betas = self.betas\n",
    "        alphas = 1 - betas\n",
    "        alphas_prod = torch.cumprod(alphas, 0)\n",
    "        alphas_prod_p = torch.cat([torch.tensor([1]).float(), alphas_prod[:-1]], 0)\n",
    "        alphas_bar_sqrt = torch.sqrt(alphas_prod)\n",
    "        one_minus_alphas_bar_log = torch.log(1 - alphas_prod)\n",
    "        one_minus_alphas_bar_sqrt = torch.sqrt(1 - alphas_prod)\n",
    "        self.register_buffer(\"alphas\", alphas)\n",
    "        self.register_buffer(\"alphas_prod\", alphas_prod)\n",
    "        self.register_buffer(\"alphas_prod_p\", alphas_prod_p)\n",
    "        self.register_buffer(\"alphas_bar_sqrt\", alphas_bar_sqrt)\n",
    "        self.register_buffer(\"one_minus_alphas_bar_log\", one_minus_alphas_bar_log)\n",
    "        self.register_buffer(\"one_minus_alphas_bar_sqrt\", one_minus_alphas_bar_sqrt)\n",
    "\n",
    "    def sample_step(self, x, t, no_var=False, langevin=False, reward=None):\n",
    "        \"\"\"\n",
    "        perform one-step sampling.\n",
    "\n",
    "        if self.ddpm_like is True, a sample is generated via diffusion-like update rule.\n",
    "            x_{t-1} = 1/sqrt{alpha_t} * (x_{t} - (1-alpha_t/sqrt{1-bar{alpha}_t}) * net(x_t,t)) + sigma_t * eps_t,\n",
    "            if False, x_{t-1} = x_t - net(x_t,t) + sigma_t * eps_t.\n",
    "\n",
    "        no_var: if True, no noise is added. usually for debugging.\n",
    "        langevin: decide direction based on the direction of the gradient of the reward.\n",
    "        reward: required for langevin=True\n",
    "        \"\"\"\n",
    "        device = x.device\n",
    "        t = process_single_t(x, t)\n",
    "        eps_theta = self(x, t)\n",
    "\n",
    "        eps_factor = (1 - extract(self.alphas, t, x)) / extract(\n",
    "            self.one_minus_alphas_bar_sqrt, t, x\n",
    "        )\n",
    "        mean = (1 / extract(self.alphas, t, x).sqrt()) * (\n",
    "            x - (eps_factor * eps_theta)\n",
    "        )\n",
    "        \n",
    "        z = torch.randn_like(x)\n",
    "        sigma_t = extract(self.betas, t, x).sqrt()\n",
    "        if no_var:\n",
    "            sample = mean\n",
    "        else:\n",
    "            sample = mean + sigma_t * z\n",
    "        dist = Normal(mean, sigma_t)\n",
    "        log_prob = dist.log_prob(sample.detach()).sum(-1)\n",
    "        return {\n",
    "            \"sample\": sample,\n",
    "            \"log_prob\": log_prob,\n",
    "            \"vel\": eps_theta,\n",
    "            \"mean\": mean,\n",
    "            \"sigma\": sigma_t,\n",
    "        }\n",
    "\n",
    "    def sample(self, n_sample, device=\"cpu\", no_var=False):\n",
    "        x = torch.randn(n_sample, *self.sample_shape).to(device)\n",
    "        l_x = [x]\n",
    "        l_vel = []\n",
    "        log_probs = []\n",
    "\n",
    "        for t in reversed(range(self.n_timesteps)):\n",
    "            t = torch.tensor([t]).to(device)\n",
    "            d_step = self.sample_step(x, t, no_var=no_var)\n",
    "            x, vel, log_prob, mu, sigma = (\n",
    "                d_step[\"sample\"],\n",
    "                d_step[\"vel\"],\n",
    "                d_step[\"log_prob\"],\n",
    "                d_step[\"mean\"],\n",
    "                d_step[\"sigma\"],\n",
    "            )\n",
    "            log_probs.append(log_prob)\n",
    "            l_x.append(x)\n",
    "            l_vel.append((vel**2).view(len(x), -1).sum(-1))\n",
    "\n",
    "        log_prob = torch.stack(log_probs, dim=1)  # N x T\n",
    "        d_sample = {\n",
    "            \"sample\": x,\n",
    "            \"l_sample\": l_x,\n",
    "            \"log_prob\": log_prob,\n",
    "        }\n",
    "        return d_sample\n",
    "\n",
    "    def log_prob(self, l_x):\n",
    "        \"\"\"evaluate policy probability given trajectory\"\"\"\n",
    "        assert len(l_x) == self.n_timesteps + 1\n",
    "        l_log_prob = []\n",
    "        for t, x in zip(reversed(range(self.n_timesteps)), l_x):\n",
    "            if t != self.n_timesteps - 1:  # skip x_T\n",
    "                log_prob = Normal(d_step[\"mean\"], d_step[\"sigma\"]).log_prob(x.detach()).sum(-1)\n",
    "                l_log_prob.append(log_prob)\n",
    "            d_step = self.sample_step(x.detach(), t)\n",
    "        x_last = l_x[-1]\n",
    "        log_prob = Normal(d_step[\"mean\"], d_step[\"sigma\"]).log_prob(x_last.detach()).sum(-1)\n",
    "        l_log_prob.append(log_prob)\n",
    "        return torch.stack(l_log_prob, dim=1)  # N x T\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        return self.sampler(x, t)\n",
    "\n",
    "    def train_step_diffusion(self, x, opt):\n",
    "        opt.zero_grad()\n",
    "        loss = self.noise_estimation_loss(x)\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(self.parameters(), 1)\n",
    "        opt.step()\n",
    "        d_train = {\"loss\": loss.item()}\n",
    "        return d_train\n",
    "\n",
    "    def noise_estimation_loss(self, x_0):\n",
    "        batch_size = x_0.shape[0]\n",
    "        # Select a random step for each example\n",
    "        t = torch.randint(0, self.n_timesteps, size=(batch_size,))\n",
    "        # x0 multiplier\n",
    "        a = extract(self.alphas_bar_sqrt, t, x_0)\n",
    "        # eps multiplier\n",
    "        am1 = extract(self.one_minus_alphas_bar_sqrt, t, x_0)\n",
    "        e = torch.randn_like(x_0)\n",
    "        # model input\n",
    "        x = x_0 * a + e * am1\n",
    "        output = self(x, t)\n",
    "        return (e - output).square().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0609dfe-85c5-4fb0-8e13-cf335efd16ea",
   "metadata": {},
   "source": [
    "## 4. Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e20235-02bd-4abe-bbda-e0e63eb27cb1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class ConditionalLinear(nn.Module):\n",
    "    \"\"\"from https://github.com/UW-Madison-Lee-Lab/SFT-PG/blob/main/toy_exp/models.py\n",
    "    Original source seems to be https://github.com/acids-ircam/diffusion_models\n",
    "\n",
    "    prediction from x given conditional information y\"\"\"\n",
    "    def __init__(self, num_in, num_out, n_steps):\n",
    "        super(ConditionalLinear, self).__init__()\n",
    "        self.num_out = num_out\n",
    "        self.lin = nn.Linear(num_in, num_out)\n",
    "        self.embed = nn.Embedding(n_steps, num_out)\n",
    "        self.embed.weight.data.uniform_()\n",
    "        torch.nn.init.xavier_normal_(self.lin.weight)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        out = self.lin(x)\n",
    "        gamma = self.embed(y)\n",
    "        out = gamma.view(-1, self.num_out) * out\n",
    "        return out\n",
    "\n",
    "\n",
    "class ConditionalModel(nn.Module):\n",
    "    \"\"\"modified from https://github.com/UW-Madison-Lee-Lab/SFT-PG/blob/main/toy_exp/models.py\"\"\"\n",
    "    def __init__(self, in_dim, out_dim, n_steps, n_hidden=128):\n",
    "        super(ConditionalModel, self).__init__()\n",
    "        self.lin1 = ConditionalLinear(in_dim, n_hidden, n_steps)\n",
    "        self.lin2 = ConditionalLinear(n_hidden, n_hidden, n_steps)\n",
    "        self.lin3 = ConditionalLinear(n_hidden, n_hidden, n_steps)\n",
    "        self.lin4 = nn.Linear(n_hidden, out_dim)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        x = F.softplus(self.lin1(x, y))\n",
    "        x = F.softplus(self.lin2(x, y))\n",
    "        x = F.softplus(self.lin3(x, y))\n",
    "        return self.lin4(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c8091b-569b-43c9-99d4-696ba06c0e98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Positional embedding for time\n",
    "\"\"\"\n",
    "\n",
    "# Fully Connected Network\n",
    "def get_activation(s_act):\n",
    "    if s_act == 'relu':\n",
    "        return nn.ReLU(inplace=True)\n",
    "    elif s_act == 'sigmoid':\n",
    "        return nn.Sigmoid()\n",
    "    elif s_act == 'softplus':\n",
    "        return nn.Softplus()\n",
    "    elif s_act == 'linear':\n",
    "        return None\n",
    "    elif s_act == 'tanh':\n",
    "        return nn.Tanh()\n",
    "    elif s_act == 'leakyrelu':\n",
    "        return nn.LeakyReLU(0.2, inplace=True)\n",
    "    elif s_act == 'softmax':\n",
    "        return nn.Softmax(dim=1)\n",
    "    elif s_act == 'swish':\n",
    "        return nn.SiLU(inplace=True)\n",
    "    else:\n",
    "        raise ValueError(f'Unexpected activation: {s_act}')\n",
    "\n",
    "        \n",
    "class FCNet(nn.Module):\n",
    "    \"\"\"fully-connected network\"\"\"\n",
    "    def __init__(self,\n",
    "            in_dim,\n",
    "            out_dim,\n",
    "            l_hidden=(50,),\n",
    "            activation='sigmoid',\n",
    "            out_activation='linear',\n",
    "            bias=True):\n",
    "        super().__init__()\n",
    "        l_neurons = tuple(l_hidden) + (out_dim,)\n",
    "        if isinstance(activation, str):\n",
    "            activation = (activation,) * len(l_hidden)\n",
    "        activation = tuple(activation) + (out_activation,)\n",
    "\n",
    "        l_layer = []\n",
    "        prev_dim = in_dim\n",
    "        for i_layer, (n_hidden, act) in enumerate(zip(l_neurons, activation)):\n",
    "            l_layer.append(nn.Linear(prev_dim, n_hidden, bias=bias))\n",
    "            act_fn = get_activation(act)\n",
    "            if act_fn is not None:\n",
    "                l_layer.append(act_fn)\n",
    "            prev_dim = n_hidden\n",
    "\n",
    "        self.net = nn.Sequential(*l_layer)\n",
    "        self.in_dim = in_dim\n",
    "        self.out_shape = (out_dim,)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "    \n",
    "\n",
    "def get_timestep_embedding(timesteps, embedding_dim: int):\n",
    "    \"\"\"\n",
    "    From Fairseq.\n",
    "    Build sinusoidal embeddings.\n",
    "    This matches the implementation in tensor2tensor, but differs slightly\n",
    "    from the description in Section 3.5 of \"Attention Is All You Need\".\n",
    "    \"\"\"\n",
    "    assert len(timesteps.shape) == 1\n",
    "\n",
    "    half_dim = embedding_dim // 2\n",
    "    emb = math.log(10000) / (half_dim - 1)\n",
    "    emb = torch.exp(torch.arange(half_dim, dtype=torch.float) * -emb)\n",
    "    emb = timesteps.type(dtype=torch.float)[:, None] * emb[None, :].to(timesteps.device)\n",
    "    emb = torch.cat([torch.sin(emb), torch.cos(emb)], axis=1)\n",
    "    if embedding_dim % 2 == 1:  # zero pad\n",
    "        emb = torch.pad(emb, [0, 1], value=0.0)\n",
    "    assert emb.shape == (timesteps.shape[0], embedding_dim)\n",
    "    return emb\n",
    "\n",
    "\n",
    "def process_single_t(x, t):\n",
    "    \"\"\"make single integer t into a vector of an appropriate size\"\"\"\n",
    "    if isinstance(t, int) or len(t.shape) == 0 or len(t) == 1:\n",
    "        t = torch.ones([x.shape[0]], dtype=torch.long, device=x.device) * t\n",
    "    return t\n",
    "\n",
    "\n",
    "class FCNet_temb(nn.Module):\n",
    "    def __init__(\n",
    "        self, in_dim, out_dim, hidden_dim=128, t_emb_dim=32, activation=\"relu\", spec_norm=False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.net1 = FCNet(\n",
    "            in_dim=in_dim,\n",
    "            out_dim=hidden_dim,\n",
    "            l_hidden=[],\n",
    "            activation=activation,\n",
    "            out_activation=\"linear\",\n",
    "        )\n",
    "        self.net2 = FCNet(\n",
    "            in_dim=t_emb_dim,\n",
    "            out_dim=hidden_dim,\n",
    "            l_hidden=(hidden_dim, hidden_dim),\n",
    "            activation=activation,\n",
    "            out_activation=\"linear\",\n",
    "        )\n",
    "        self.net3 = FCNet(\n",
    "            in_dim=2 * hidden_dim,\n",
    "            out_dim=out_dim,\n",
    "            l_hidden=(hidden_dim, hidden_dim),\n",
    "            activation=activation,\n",
    "            out_activation=\"linear\",\n",
    "        )\n",
    "        self.t_emb_dim = t_emb_dim\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        if len(x.shape) == 4:\n",
    "            x = x.view(x.shape[0], -1)\n",
    "        x_ = self.net1(x)\n",
    "        t = process_single_t(x, t)\n",
    "        t_emb = get_timestep_embedding(t, self.t_emb_dim).to(x.device)\n",
    "        t_emb = self.net2(t_emb)\n",
    "        x_ = torch.cat([x_, t_emb], dim=1)\n",
    "        return self.net3(x_)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06f8113-9b27-45ff-b73c-6f241039b2d4",
   "metadata": {},
   "source": [
    "## 5. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662ee40e-65c4-4d1d-917b-7643154660a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b15539-44f0-4621-8ce9-853a1c2e6836",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_timesteps = 10\n",
    "# sampler = ConditionalModel(in_dim=2, out_dim=2, n_steps=5, n_hidden=128)\n",
    "sampler = FCNet_temb(in_dim=2, out_dim=2, t_emb_dim=128, activation='relu')\n",
    "model = DDPM(sampler=sampler, sample_shape=(2,), n_timesteps=n_timesteps, \n",
    "            beta_schedule='linear', beta_start=1e-5, beta_end=1e-2,)\n",
    "opt = Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "l_loss = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0658a1ac-cf73-45b2-bab8-b4ec06faaf40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_iter = 4\n",
    "for i_iter in tqdm(range(n_iter)):\n",
    "    x = torch.tensor(sample2d('8gaussians', 100, scale_factor=1.))\n",
    "    d_train = model.train_step_diffusion(x, opt)\n",
    "    l_loss.append(d_train['loss'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70121a3f-6e7d-46d8-9b6e-642d720faa88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(l_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4a2f66-7923-403d-8ac2-cba80eee311a",
   "metadata": {},
   "source": [
    "## 6. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f11db5-d6bf-4b53-bf6b-2f1c3c257f14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_sample = 1000\n",
    "d_sample = model.sample(n_sample=n_sample, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4350b5ed-b04f-4282-9c6d-b1f2732af588",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s = d_sample['sample'].detach()\n",
    "plt.scatter(s[:, 0], s[:, 1], s=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0782e2-588a-42c1-ba2d-3a7acd050504",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''comparison'''\n",
    "x_true = torch.tensor(sample2d(dataset, 1000, scale_factor=1.))\n",
    "\n",
    "plt.scatter(s[:,0], s[:,1], s=1, label='Sample')\n",
    "plt.scatter(x_true[:,0], x_true[:,1], s=1, label='Data')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9177f66a-890c-4785-9a41-02ef659fb24f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! pip install pot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3161e82e-569c-4b0f-9a7c-33b9c7781487",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# '''for quantitative evaluation'''\n",
    "# import ot\n",
    "\n",
    "# n_sample = 10000\n",
    "# d_sample = model.sample(n_sample=n_sample, device=device)\n",
    "# s = d_sample['sample'].detach()\n",
    "# x_true = torch.tensor(sample2d(dataset, n_sample, scale_factor=1.))\n",
    "# w_dis = ot.sliced_wasserstein_distance(x_true, s, n_projections=1000, p=2).item()\n",
    "# print(w_dis)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nae]",
   "language": "python",
   "name": "conda-env-nae-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
